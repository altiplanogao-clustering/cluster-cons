---

- set_fact:
    pkg_ic:
      name: spark
      install_path: '{{ spark_conf.install_dir }}'
      url: '{{ spark_res.url }}'
      file: '{{ spark_res.file }}'
      basename: '{{ spark_res.basename }}'
    spark_path: '{{ spark_conf.install_dir }}/{{ spark_res.basename}}'
# delete spark installation, configuration and data
- name: delete spark installation
  file: path="{{ spark_path }}" state=absent
  when: (fresh_unzip is defined) and fresh_unzip
- name: delete spark_res_dir
  file: path="{{ spark_res_dir }}" state=absent
  when: (fresh_unzip is defined) and fresh_unzip

# install spark files
- name: Present install path '{{ "[" }}{{ pkg_ic.install_path }}{{ "]" }}'
  file: path="{{ pkg_ic.install_path }}" state=directory
- name: Download {{ pkg_ic.file }}
  cached_get_url:
    cached: "{{ resource_cache }}/{{ pkg_ic.file }}"
    url: "{{ pkg_ic.url }}"
    dest: '{{ pkg_ic.install_path }}/{{ pkg_ic.file }}'
- name: Unarchive package
  unarchive:
    src: "{{ pkg_ic.install_path }}/{{ pkg_ic.file }}"
    dest: "{{ pkg_ic.install_path }}"
    remote_src: yes

# export HADOOP environment variables
- name: export SPARK_HOME ...
  blockinfile:
    path: /etc/environment
    marker: "# {mark} SPARK BLOCK"
    block: |
      SPARK_HOME={{ spark_path }}
- name: export SPARK_HOME ... 
  blockinfile:
    path: "{{ sys_profile }}"
    marker: "# {mark} SPARK BLOCK"
    block: |
      export SPARK_HOME={{ spark_path }}

#  when: ansible_os_family == "RedHat"
- name: export SPARK_HOME to PATH
  lineinfile:
    dest: '{{ sys_profile }}'
    line: 'export PATH=$SPARK_HOME/bin:$PATH'
# - name: fetch JAVA_HOME
#   command: /bin/bash -l -c "echo $JAVA_HOME"
#   changed_when: false
#   register: fetch_java_home
# - debug: msg="JAVA_HOME={{ fetch_java_home.stdout}}"
# - name: set spark JAVA_HOME
#   lineinfile:
#     dest: "{{ spark_path }}/etc/spark/spark-env.sh"
#     regexp: '^export JAVA_HOME='
#     line: 'export JAVA_HOME={{ fetch_java_home.stdout}}'

