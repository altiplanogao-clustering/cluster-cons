---

- set_fact:
    spark_path: '{{ spark_conf.install_dir }}/{{ spark_res.basename}}'
# delete spark installation, configuration and data
- name: delete spark installation
  file: path="{{ spark_path }}" state=absent
  when: (fresh_unzip is defined) and fresh_unzip
- name: delete spark_res_dir
  file: path="{{ spark_res_dir }}" state=absent
  when: (fresh_unzip is defined) and fresh_unzip

# install spark files
- name: mkdir spark
  file: path="{{ spark_conf.install_dir }}" state=directory
- name: upload spark tar file
  copy:
    src: "{{ role_path }}/{{ rcpath }}/{{ spark_res.tar_file }}"
    dest: "{{ spark_conf.install_dir }}/{{ spark_res.tar_file }}"
- name: check unarchive spark directory
  stat: path="{{ spark_path }}"
  register: sparkfstat
- name: unarchive spark
  unarchive:
    src: "{{ spark_conf.install_dir }}/{{ spark_res.tar_file }}"
    dest: "{{ spark_conf.install_dir }}"
    remote_src: True
  when: sparkfstat.stat.isdir is not defined

# export HADOOP environment variables
# - name: export HADOOP_HOME, HADOOP_PREFIX ...
#   blockinfile:
#     path: /etc/environment
#     marker: "# {mark} HADOOP BLOCK"
#     block: |
#       HADOOP_HOME={{ spark_path }}
#       HADOOP_PREFIX={{ spark_path }}
#       HADOOP_HDFS_HOME={{ spark_path }}
#       HADOOP_YARN_HOME={{ spark_path }}
# - name: export HADOOP_HOME, HADOOP_PREFIX ... (for RedHat)
#   blockinfile:
#     path: "{{ sys_profile }}"
#     marker: "# {mark} HADOOP BLOCK"
#     block: |
#       export HADOOP_HOME={{ spark_path }}
#       export HADOOP_PREFIX={{ spark_path }}
#       export HADOOP_HDFS_HOME={{ spark_path }}
#       export HADOOP_YARN_HOME={{ spark_path }}

# #  when: ansible_os_family == "RedHat"
# - name: export HADOOP_HOME to PATH
#   lineinfile:
#     dest: '{{ sys_profile }}'
#     line: 'export PATH=$PATH:$HADOOP_HOME/bin'
# - name: fetch JAVA_HOME
#   command: /bin/bash -l -c "echo $JAVA_HOME"
#   changed_when: false
#   register: fetch_java_home
# - debug: msg="JAVA_HOME={{ fetch_java_home.stdout}}"
# - name: set spark JAVA_HOME
#   lineinfile:
#     dest: "{{ spark_path }}/etc/spark/spark-env.sh"
#     regexp: '^export JAVA_HOME='
#     line: 'export JAVA_HOME={{ fetch_java_home.stdout}}'

