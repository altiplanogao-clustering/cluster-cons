---

- set_fact:
    temp_ic:
      name: spark
      install_path: '{{ spark_conf.install_dir }}'
      url: '{{ spark_res.url }}'
      file: '{{ spark_res.file }}'
      basename: '{{ spark_res.basename }}'
    spark_path: '{{ spark_conf.install_dir }}/{{ spark_res.basename}}'
# delete spark installation, configuration and data
- name: delete spark installation
  file: path="{{ spark_path }}" state=absent
  when: (fresh_unzip is defined) and fresh_unzip
- name: delete spark_res_dir
  file: path="{{ spark_res_dir }}" state=absent
  when: (fresh_unzip is defined) and fresh_unzip

# install spark files

- name: download and unzip
  include_role:
    name: basic/download_and_unzip
  vars:
    pkg_conf: '{{ temp_ic }}'

# export HADOOP environment variables
- name: export SPARK_HOME ...
  blockinfile:
    path: /etc/environment
    marker: "# {mark} SPARK BLOCK"
    block: |
      SPARK_HOME={{ spark_path }}
- name: export SPARK_HOME ... 
  blockinfile:
    path: "{{ sys_profile }}"
    marker: "# {mark} SPARK BLOCK"
    block: |
      export SPARK_HOME={{ spark_path }}

#  when: ansible_os_family == "RedHat"
- name: export SPARK_HOME to PATH
  lineinfile:
    dest: '{{ sys_profile }}'
    line: 'export PATH=$PATH:$SPARK_HOME/bin'
# - name: fetch JAVA_HOME
#   command: /bin/bash -l -c "echo $JAVA_HOME"
#   changed_when: false
#   register: fetch_java_home
# - debug: msg="JAVA_HOME={{ fetch_java_home.stdout}}"
# - name: set spark JAVA_HOME
#   lineinfile:
#     dest: "{{ spark_path }}/etc/spark/spark-env.sh"
#     regexp: '^export JAVA_HOME='
#     line: 'export JAVA_HOME={{ fetch_java_home.stdout}}'

